{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 1  # number of classes\n",
    "img_width, img_height = 224, 224  # change based on the shape/structure of your images\n",
    "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 50  # number of iteration the algorithm gets trained.\n",
    "learn_rate = 1e-5  # sgd learning rate\n",
    "\n",
    "train_dir = '/home/skkulab/ICCV/Dataset/preprocessed_dataset/train'\n",
    "validation_dir = '/home/skkulab/ICCV/Dataset/preprocessed_dataset/validation'\n",
    "test_dir = '/home/skkulab/ICCV/Dataset/preprocessed_dataset/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/skkulab/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "img_input = Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "x = Conv2D(96, 11, strides=4, padding='same', use_bias=False)(img_input) # 15\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Conv2D(256, 5, strides=1, padding='same', use_bias=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x) # 8\n",
    "\n",
    "x = Conv2D(384, 3, strides=1, padding='same', use_bias=False)(x) # 15\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x) # 8\n",
    "\n",
    "x = Conv2D(384, 3, strides=1, padding='same', use_bias=False)(x) # 15\n",
    "x = Activation('relu')(x)\n",
    "x = Conv2D(256, 3, strides=1, padding='same', use_bias=False)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "model_out = MaxPooling2D(pool_size=3, strides=2, padding='valid')(x) # 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 96)        34848     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 256)       614400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 27, 27, 384)       884736    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 27, 384)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 384)       1327104   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 256)       884736    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,802,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Add fully connected layer\n",
    "x = GlobalAveragePooling2D()(model_out)\n",
    "x = Dense(4096, activation=None)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(1, activation=None)(x)\n",
    "out = Activation('sigmoid')(x)\n",
    "\n",
    "model = Model(img_input, out)\n",
    "print(model.summary())\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=learn_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing train, validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 251702 images belonging to 2 classes.\n",
      "Found 28298 images belonging to 2 classes.\n",
      "Found 17714 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=True,\n",
    "                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes = test_generator.classes\n",
    "\n",
    "len(test_classes[test_classes == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model(weight unfreezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "callback_list = [EarlyStopping(monitor='val_acc', patience=5),\n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/skkulab/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "100/100 [==============================] - 118s 1s/step - loss: 0.6445 - acc: 0.5228 - val_loss: 0.4965 - val_acc: 0.6505\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.2281 - acc: 0.9353 - val_loss: 0.1253 - val_acc: 0.9619\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=100,\n",
    "                             epochs=2,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=len(validation_generator),\n",
    "                             callbacks=callback_list,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tune model(weight freezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(directory, batch_size=32):\n",
    "    folder =  np.sort(os.listdir(directory))\n",
    "    real_img = np.asarray(glob.glob(directory + '/' + folder[0]+'/*.png'))\n",
    "    real_idx = np.arange(len(real_img))\n",
    "    \n",
    "    while 1:\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        y = []\n",
    "        \n",
    "        if (len(real_idx) < batch_size):\n",
    "            real_idx = np.arange(len(real_img))\n",
    "            continue\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            if (len(real_idx) < batch_size):\n",
    "                real_idx = np.arange(len(real_img))\n",
    "                break\n",
    "            random1 = np.random.choice(real_idx, 1, replace=False)\n",
    "            real_idx = real_idx[~np.isin(real_idx, random1)]\n",
    "            random2 = np.random.choice(real_idx, 1, replace=False)\n",
    "            real_idx = real_idx[~np.isin(real_idx, random2)]\n",
    "            X1.append(np.asarray(Image.open(real_img[random1[0]]).convert(\"RGB\"))/255.)\n",
    "            X2.append(np.asarray(Image.open(real_img[random2[0]]).convert(\"RGB\"))/255.)\n",
    "            y.append(np.array([0.]))\n",
    "\n",
    "        X1 = np.asarray(X1)\n",
    "        X2 = np.asarray(X2)\n",
    "        y = np.asarray(y)\n",
    "        yield [X1, X2], y\n",
    "        \n",
    "def generator_res(ft_dir, directory, batch_size=32):\n",
    "    folder = np.sort(os.listdir(directory))\n",
    "    real_img = np.asarray(glob.glob(ft_dir + '/' + '0' +'/*.png'))\n",
    "    real_idx = np.arange(len(real_img))\n",
    "    random1 = np.random.choice(real_idx, 1, replace=False)\n",
    "    img = np.asarray(Image.open(real_img[random1[0]]).convert(\"RGB\"))/255.\n",
    "    fake_img = np.asarray(glob.glob(directory + '/' + folder[1] + '/*.png'))\n",
    "    fake_idx = np.arange(len(fake_img))\n",
    "    test_img = np.asarray(glob.glob(directory + '/' + folder[0] + '/*.png'))\n",
    "    test_idx = np.arange(len(test_img))\n",
    "    while 1:\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        y = []\n",
    "        if (len(fake_idx) < batch_size):\n",
    "            fake_idx = np.arange(len(fake_img))\n",
    "            continue\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            if np.random.random() < 0.95:\n",
    "            \n",
    "                if (len(fake_idx) < batch_size):\n",
    "                    fake_idx = np.arange(len(fake_img))\n",
    "                    break\n",
    "                random2 = np.random.choice(fake_idx, 1, replace=False)\n",
    "                fake_idx = fake_idx[~np.isin(fake_idx, random2)]\n",
    "                X1.append(img)\n",
    "                X2.append(np.asarray(Image.open(fake_img[random2[0]]).convert(\"RGB\"))/255.)\n",
    "                y.append(np.array([1.]))\n",
    "            \n",
    "            else:\n",
    "                if (len(test_idx) < batch_size):\n",
    "                    test_idx = np.arange(len(test_img))\n",
    "                random3 = np.random.choice(test_idx, 1, replace=False)\n",
    "                test_idx = test_idx[~np.isin(test_idx, random3)]\n",
    "                X1.append(img)\n",
    "                X2.append(np.asarray(Image.open(test_img[random3[0]]).convert(\"RGB\"))/255.)\n",
    "                y.append(np.array([0.]))\n",
    "\n",
    "        X1 = np.asarray(X1)\n",
    "        X2 = np.asarray(X2)\n",
    "        y = np.asarray(y)\n",
    "        yield [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manDist(x):\n",
    "    result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "    return result\n",
    "\n",
    "def euclidean_distance(inputs):\n",
    "    assert len(inputs) == 2, 'Euclidean distance needs 2 inputs, %d given' % len(inputs)\n",
    "    u, v = inputs\n",
    "    return K.sqrt(K.sum((K.square(u - v)), axis=1, keepdims=True))  \n",
    "\n",
    "def contrastive_loss(y_true,y_pred):\n",
    "    margin=1.4\n",
    "    return K.mean((1. - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0.)))\n",
    "\n",
    "def siamese_acc(y_true, y_pred):\n",
    "    return K.mean((K.equal(y_true, K.cast(y_pred > 0.4, K.floatx()))), axis=1)\n",
    "\n",
    "def y_pred_prt(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n",
    "input_seq = Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1138 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ft_dir = '/home/skkulab/ICCV/Dataset/preprocessed_dataset/fine-tune'\n",
    "ft_datagen = ImageDataGenerator(rescale=1./255)\n",
    "ft_generator = test_datagen.flow_from_directory(ft_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = Model(img_input, out)\n",
    "ft_model.set_weights(model.get_weights())\n",
    "for l in range(len(ft_model.layers) - 2):\n",
    "    ft_model.layers[l].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 96)        34848     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 256)       614400    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 27, 27, 384)       884736    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 27, 384)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 384)       1327104   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 13, 256)       884736    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              1052672   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 4,798,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ft_model.summary()\n",
    "ft_model.compile(optimizer=Adam(lr=learn_rate), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "30/30 [==============================] - 3s 116ms/step - loss: 0.1713 - acc: 0.9323\n",
      "Epoch 2/3\n",
      " 1/30 [>.............................] - ETA: 2s - loss: 0.1291 - acc: 0.9375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 3s 110ms/step - loss: 0.1638 - acc: 0.9341\n",
      "Epoch 3/3\n",
      "30/30 [==============================] - 4s 124ms/step - loss: 0.1488 - acc: 0.9382\n"
     ]
    }
   ],
   "source": [
    "history_ft = ft_model.fit_generator(ft_generator, steps_per_epoch=30, epochs=3,\n",
    "                             callbacks=callback_list, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese model (weight freezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              (None, 1)                 4802593   \n",
      "=================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 4,798,496\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_4 (Model)                 (None, 1)            4802593     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_4[1][0]                    \n",
      "                                                                 model_4[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,802,593\n",
      "Trainable params: 4,097\n",
      "Non-trainable params: 4,798,496\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = Model(img_input, out)\n",
    "base_model.set_weights(model.get_weights())\n",
    "for l in range(len(base_model.layers) - 2):\n",
    "    base_model.layers[l].trainable = False   \n",
    "\n",
    "im_in = Input(shape=(224, 224, 3))\n",
    "x1 = base_model([im_in])\n",
    "\n",
    "model_top = Model(inputs=[im_in], outputs=x1)\n",
    "model_top.summary()\n",
    "\n",
    "left_input = Input(shape=(224, 224, 3))\n",
    "right_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "h1 = model_top(left_input)\n",
    "h2 = model_top(right_input)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([h1, h2])\n",
    "siam_model = Model(inputs=[left_input, right_input], outputs=distance)\n",
    "siam_model.compile(loss=contrastive_loss, optimizer=Adam(), metrics=[siamese_acc])\n",
    "siam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = generator(ft_dir)\n",
    "test_gen = generator_res(ft_dir, test_dir, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15/15 [==============================] - 4s 285ms/step - loss: 0.0229 - siamese_acc: 0.9563\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,siamese_acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,siamese_acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 4s 242ms/step - loss: inf - siamese_acc: 0.9872\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 4s 258ms/step - loss: inf - siamese_acc: 0.9872\n"
     ]
    }
   ],
   "source": [
    "callback_list = [EarlyStopping(monitor='val_acc', patience=3),\n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)]\n",
    "output = siam_model.fit_generator(train_gen, steps_per_epoch=15, epochs=3,callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=len(test_generator))\n",
    "print('test acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator, steps=len(test_generator))\n",
    "predictions[predictions > 0.5] = 1\n",
    "predictions[predictions <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[np.isnan(predictions)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_classes = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = metrics.classification_report(true_classes, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(true_classes, predictions, pos_label=1.)\n",
    "cm = confusion_matrix(true_classes, predictions)\n",
    "recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "fallout = cm[1][0] / (cm[1][0] + cm[1][1])\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, thresholds)(eer)\n",
    "\n",
    "plt.plot(fpr, tpr, 'o-')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "plt.plot([fallout], [recall], 'ro', ms=10)\n",
    "plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.show()\n",
    "\n",
    "roc_auc_score(true_classes, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FPR=FAR\", fallout)\n",
    "print(\"FNR=FRR\", 1-recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score = []\n",
    "answer = []\n",
    "max_iter = int(16715 / 32)\n",
    "j = 0\n",
    "for i in tqdm(test_gen):\n",
    "    if j == max_iter:\n",
    "        break\n",
    "    y_score = siam_model.predict_on_batch(i[0])\n",
    "    score.append(y_score)\n",
    "    answer.append(i[1])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(answer, y_hat, pos_label=1.)\n",
    "print(roc_auc_score(answer, y_hat))\n",
    "y_hat[y_hat >= 0.81] = 1.\n",
    "y_hat[y_hat < 0.81] = 0.\n",
    "print(metrics.classification_report(answer, y_hat))\n",
    "print(confusion_matrix(answer, y_hat))\n",
    "eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "thresh = interp1d(fpr, thresholds)(eer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(answer, y_hat)\n",
    "recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "fallout = cm[1][0] / (cm[1][0] + cm[1][1])\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr, 'o-')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "plt.plot([fallout], [recall], 'ro', ms=10)\n",
    "plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FPR=FAR\", fallout)\n",
    "print(\"FNR=FRR\", 1-recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "siamese_loss, siamese_acc = siam_model.evaluate_generator(test_gen, steps=len(test_generator))\n",
    "print('test acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.savefig('/home/skkulab/ICCV/models//xcetion_v1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model train(weight unfreezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(lr=learn_rate),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=len(train_generator),\n",
    "                             epochs=nb_epoch,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=len(validation_generator),\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/home/skkulab/ICCV/models/xception_v2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model('/home/skkulab/ICCV/models/xception_v1.h5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = loaded_model.evaluate_generator(test_generator, steps=len(test_generator))\n",
    "print('test acc:', test_acc)\n",
    "print('test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = loaded_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
