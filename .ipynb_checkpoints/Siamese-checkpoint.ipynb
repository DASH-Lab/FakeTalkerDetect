{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### MaLSTM Data building ###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Conv2D, Dense, add, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Lambda, Bidirectional, Flatten, BatchNormalization, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from tqdm import tqdm, trange\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.metrics import roc_curve\n",
    "import glob\n",
    "from PIL import Image\n",
    "from keras.applications import Xception\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "\n",
    "## Norm ##\n",
    "EPOCHS = 1000\n",
    "train_dir = '/home/skkulab/ICCV/Dataset/preprocessed_dataset/train'\n",
    "validation_dir = '/home/skkulab/ICCV/Dataset/preprocessed_dataset/validation'\n",
    "test_dir = '/home/skkulab/ICCV/Dataset/preprocessed_dataset/test'\n",
    "nb_classes = 1  # number of classes\n",
    "img_width, img_height = 224, 224  # change based on the shape/structure of your images\n",
    "batch_size = 32  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 50  # number of iteration the algorithm gets trained.\n",
    "learn_rate = 1e-5  # sgd learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(directory, batch_size=32):\n",
    "    folder = os.listdir(directory)\n",
    "    real_img = np.asarray(glob.glob(directory + '/' + folder[0]+'/*.png'))\n",
    "    real_idx = np.arange(len(real_img))\n",
    "    \n",
    "    while 1:\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        y = []\n",
    "        \n",
    "        if (len(real_idx) < batch_size):\n",
    "            real_idx = np.arange(len(real_img))\n",
    "            continue\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            random1 = np.random.choice(real_idx, 1, replace=False)\n",
    "            real_idx = np.delete(real_idx, random1)\n",
    "            random2 = np.random.choice(real_idx, 1, replace=False)\n",
    "            real_idx = np.delete(real_idx, random2)\n",
    "            X1.append(np.asarray(Image.open(real_img[random1[0]]).convert(\"RGB\"))/255.)\n",
    "            X2.append(np.asarray(Image.open(real_img[random2[0]]).convert(\"RGB\"))/255.)\n",
    "            y.append(np.array([0.]))\n",
    "\n",
    "        X1 = np.asarray(X1)\n",
    "        X2 = np.asarray(X2)\n",
    "        y = np.asarray(y)\n",
    "        yield [X1, X2], y\n",
    "        \n",
    "def generator_res(directory, batch_size=32):\n",
    "    folder = os.listdir(directory)\n",
    "    real_img = np.asarray(glob.glob(directory + '/' + folder[0]+'/*.png'))\n",
    "    real_idx = np.arange(len(real_img))\n",
    "    fake_img = np.asarray(glob.glob(directory + '/' + folder[1] + '/*.png'))\n",
    "    fake_idx = np.arange(len(real_img))\n",
    "    \n",
    "    while 1:\n",
    "        X1 = []\n",
    "        X2 = []\n",
    "        y = []\n",
    "        if (len(real_idx) < batch_size):\n",
    "            real_idx = np.arange(len(real_img))\n",
    "            continue\n",
    "        if (len(fake_idx) < batch_size):\n",
    "            fake_idx = np.arange(len(fake_img))\n",
    "            continue\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            random1 = np.random.choice(real_idx, 1, replace=False)\n",
    "            real_idx = np.delete(real_idx, random1)\n",
    "            random2 = np.random.choice(real_idx, 1, replace=False)\n",
    "            fake_idx = np.delete(fake_idx, random2)\n",
    "            X1.append(np.asarray(Image.open(real_img[random1[0]]).convert(\"RGB\"))/255.)\n",
    "            X2.append(np.asarray(Image.open(fake_img[random2[0]]).convert(\"RGB\"))/255.)\n",
    "            y.append(np.array([1.]))\n",
    "\n",
    "        X1 = np.asarray(X1)\n",
    "        X2 = np.asarray(X2)\n",
    "        y = np.asarray(y)\n",
    "        yield [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = generator(train_dir)\n",
    "val_gen = generator(validation_dir)\n",
    "test_gen = generator_res(test_dir, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def manDist(x):\n",
    "    result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "    return result\n",
    "\n",
    "def euclidean_distance(inputs):\n",
    "    assert len(inputs) == 2, 'Euclidean distance needs 2 inputs, %d given' % len(inputs)\n",
    "    u, v = inputs\n",
    "    return K.sqrt(K.sum((K.square(u - v)), axis=1, keepdims=True))  \n",
    "\n",
    "def contrastive_loss(y_true,y_pred):\n",
    "    margin=0.5\n",
    "    return K.mean((1. - y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0.)))\n",
    "\n",
    "def siamese_acc(y_true, y_pred):\n",
    "    return K.mean((K.equal(y_true, K.cast(y_pred > 0.4, K.floatx()))), axis=1)\n",
    "\n",
    "def y_pred_prt(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n",
    "input_seq = Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/skkulab/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "out = Dense(nb_classes, activation=None)(x)\n",
    "xception_pop = Model(base_model.input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/skkulab/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2049        global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 20,809,001\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception = load_model(\"/home/skkulab/ICCV/models/xception_v3.h5\")\n",
    "xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 443788.73it/s]\n"
     ]
    }
   ],
   "source": [
    "## freeze & L2 disatnace & loss ##\n",
    "xception.trainable = True\n",
    "for i in trange(len(xception.layers) - 2):\n",
    "    xception.layers[i].trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1)                 20863529  \n",
      "=================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 1)            20863529    input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_2[1][0]                    \n",
      "                                                                 model_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,863,529\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "im_in = Input(shape=(224, 224, 3))\n",
    "x1 = xception([im_in])\n",
    "\n",
    "model_top = Model(inputs=[im_in], outputs=x1)\n",
    "model_top.summary()\n",
    "\n",
    "left_input = Input(shape=(224, 224, 3))\n",
    "right_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "h1 = model_top(left_input)\n",
    "h2 = model_top(right_input)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([h1, h2])\n",
    "model = Model(inputs=[left_input, right_input], outputs=distance)\n",
    "model.compile(loss=contrastive_loss, optimizer=Adam(), metrics=['acc'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 100s 3s/step - loss: 0.1192 - acc: 0.8417 - val_loss: 1.6663e-14 - val_acc: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "callback_list = [EarlyStopping(monitor='val_acc', patience=3),\n",
    "                 ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)]\n",
    "output = model.fit_generator(val_gen, steps_per_epoch=30, epochs=3,\n",
    "                             validation_data=val_gen, validation_steps=100,\n",
    "                             callbacks=callback_list, workers=2, use_multiprocessing=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(\"siam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot(output.history['acc'])\n",
    "plt.plot(output.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(212)\n",
    "plt.plot(output.history['loss'])\n",
    "plt.plot(output.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:75: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:77: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0003379880920116799, 0.8950000017881393]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.save(\"siam.h5\")\n",
    "# model =load_model(\"siam.h5\")\n",
    "model.evaluate_generator(val_t_gen, steps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:75: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "/home/skkulab/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:77: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "answer = []\n",
    "j = 0\n",
    "for i in val_t_gen:\n",
    "    print(j)\n",
    "    if j == 60:\n",
    "        break\n",
    "    score.append(model.predict_on_batch(i[0]))\n",
    "    answer.append(i[1])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "cm = confusion_matrix(i[1], y_hat)\n",
    "recall = cm[0][0] / (cm[0][0] + cm[0][1])\n",
    "fallout = cm[1][0] / (cm[1][0] + cm[1][1])\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr, 'o-')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"random guess\")\n",
    "plt.plot([fallout], [recall], 'ro', ms=10)\n",
    "plt.xlabel('False Positive Rate (Fall-Out)')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"FPR=FAR\", fallout)\n",
    "print(\"FNR=FRR\", 1-recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_generator(test_gen, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
